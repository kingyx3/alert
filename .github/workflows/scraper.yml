name: Scraper

on:
  workflow_dispatch: # Allow manual triggering
    inputs:
      scraping_url:
        description: 'URL to scrape'
        required: false
        type: string

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install system dependencies for Selenium
      run: |
        sudo apt-get update
        sudo apt-get install -y wget gnupg
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable

    - name: Install Python dependencies
      run: pip install -r requirements.txt
        
    - name: Run scraper with Selenium automation
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHANNEL_ID: ${{ secrets.TELEGRAM_CHANNEL_ID }}
        SCRAPING_URL: ${{ inputs.scraping_url || vars.SCRAPING_URL }}
        # Set to "true" to disable selenium automation if needed
        DISABLE_SELENIUM_AUTOMATION: ${{ vars.DISABLE_SELENIUM_AUTOMATION || 'false' }}
      run: |
        python scraper.py

    - name: Upload debugging screenshots
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: selenium-screenshots-${{ github.run_number }}
        path: screenshots/
        retention-days: 30
        if-no-files-found: ignore

    - name: Upload automation results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: automation-results-${{ github.run_number }}
        path: |
          automation_results_*.json
          available_products_*.json
          raw_payload_*.json
        retention-days: 30
        if-no-files-found: ignore
